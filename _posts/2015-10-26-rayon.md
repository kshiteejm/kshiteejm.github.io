---
layout: post
title: Reservation-based Scheduling&#58; If You're Late Don't Blame Us!
description:
tags: paper-summary-big-data-scheduling
comments: true
---

Takeaways from *Reservation-based Scheduling: If You're Late Don't Blame Us!, C. Curino, D.E. Difallah, C. Douglas, S. Krishnan, R. Ramakrishnan, S. Rao, SoCC 2014.*

The authors propose *Rayon*, a reservation-based scheduler. 

**Goals.**

- Maximize cluster utilization and hence Return-on-Investment (ROI)
- Be workload aware. Typically adhere to the requirements of two classes of jobs in company workloads.
	- Respect completion deadlines for *Production jobs*. These are large and long running with strict service-level agreements (SLA). These jobs constitute 5% of all the jobs but consume 90% of the resources (yet another instance of the Pareto principle!).
	- Provide least possible completion latency for *Best-effort jobs*. These are abundant but smaller jobs without explicit SLAs due to their inherent interactive nature.

Existing schedulers are lacking on several fronts.

- Current schedulers are time-agnostic offering sharing policies based on priority, fairness and capacity. 
- This leads to inefficiencies and ad-hoc workarounds such as overprovisioning and manual monitoring for completion of production jobs within deadlines.
- Cannot support a mix of workloads, such as those requiring gang semantics or inter-job dependencies.

Rayon addresses these issues via a time-predictable resource allocation mechanism that meets SLAs, minimizes best effort job latency and maximizes cluster utilization.

**Rayon consists of three main stages.**

- Reservation. This involves specifying and understanding the diverse workload requirements. To do this the authors propose the *Reservation Definition Language (RDL)*. 
	- RDL is envisioned as a composition of atomic expressions (representing each task) of the form *atom(b,g,h,l,w)*, where, 
		* *b* is a vector of resource requirements per unit of the job
		* *g* is the minimum number of parallel bundles required
		* *h* is the maximum number of parallel bundles supported
		* *l* is the minimum lease duration of each allocation
		* *w* represents the total work to be done by the job
	- These expressions can support malleable jobs as MapReduce (g, l = 1) as well as strict gang jobs as MPI (g = h, l = w/h).
	- RDL also proposes several operators for composition of expressions. 
		* *window operator* enables SLA specification by capturing start (s) and end (e) time.
		* *order / all /any operators* enable specification of inter-job dependencies or choices.
- Planning. Planning involves assigning temporal and resource allocations for all the reservations. The planning problem is modeled as a Mixed-Integer Linear Program (MILP). The planning stage involves a combination of MILP and heuristics (GREE-L) to yield a practical, near-optimal and timely solution.
	- MILP. The problem is formalized as an optimization problem minimizing the cost of an allocation subject to capacity (bounded $$\Sigma b$$), parallelism (g,h) and SLA (l,w,s,e) constraints. I discuss more about this in the latter part of this summary on [MILP in Rayon](http://kshiteej.in/2015/10/26/rayon/#milp).
	- Procrastinating heuristic (GREE). The job allocation is done as near to the job completion deadline as possible. GREE finds the tallest, rightmost allocation for each of the job.
	- Lower preemption heuristic (GREE-L). The job allocation is much smoother to avoid job preemptions at the cost of reduced job acceptance (in other words job SLA violations). Allocation per job is as flat as possible.
	- MILP is used most-often in an *offline* manner, to reorganize already accepted jobs.
	- Heuristics are most-often used in an *online* manner, to commit to accept/reject incoming stream of jobs.
- Adaptive Scheduling. This involves dynamic rearrangement of Plan in response to changes in cluster capacity (because of node failures) and job expectations (because reservation request are approximate in nature).

**Rayon Architecture.**

- Rayon is implemented as an extension of YARN components and delegates several of its functional steps to different YARN components.
	- Job Managers (JM) for each job. This mainly implements the Reservation stage.
	- Node Managers (NM) running on each worker node.
	- A central Resource Manager (RM). This mainly implements the Planning and Adaptive Scheduling stage.
- Rayon consists of the following logical series of steps.
	1. JM converts the estimated demand for incoming job to RDL expressions and submits to RM.
	2. *Planner* in RM validates the reservation and determines feasibility of accepting the reservation. A realtime feedback is sent to the JM accepting or rejecting the job.
	3. *Scheduler* in RM dispatches resources based on sharing policies and job preferences. *PlanFollower* monitors cluster conditions and converts job deliverables to modified runtime parameter assignments.
	4. JM receives access to resources from the RM when the job is ready to run. JM coordinates with the NM.
	5. *Adapter* and *PlanFollower* in RM are responsible for adaptive scheduling. Job progress and cluster conditions are monitored to rerun *Planner* in offline mode for already accepted jobs to re-adjust accepted jobs.

-----

<h3 id='milp'>MILP in Rayon</h3>

$$ 
minimize \sum_{j,t} c_{j,t} * x_{j,t}
subject to: 
\forall t : \sum_{j} x_{j,t} \le Cap_t
\forall j \forall t : x_{j,t} \le h_j
\forall j : \sum_{s_j \lt f_j}  x_{j,t} = w_j
\forall j,t : x_{j,t} \in R^{+}
$$